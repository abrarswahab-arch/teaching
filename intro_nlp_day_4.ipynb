{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankuj/teaching/blob/main/intro_nlp_day_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXuvGMYIiVf8"
      },
      "source": [
        "\n",
        "<br>\n",
        "====================================================<br>\n",
        "RNN Improvements Practical<br>\n",
        "Vanishing/Exploding Gradients, GRUs and LSTMs<br>\n",
        "====================================================<br>\n",
        "Learning Goals:<br>\n",
        "- Understand vanishing and exploding gradients in RNNs<br>\n",
        "- Apply gradient clipping as a solution<br>\n",
        "- Implement GRU and LSTM for text classification<br>\n",
        "- Compare GRU vs LSTM on IMDB Sentiment Dataset<br>\n",
        "====================================================<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luaWkqVQiVgB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-5_jal8iVgD"
      },
      "source": [
        "====================================================<br>\n",
        "TASK 1 — Conceptual<br>\n",
        "===================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgmxt9v0iVgE"
      },
      "source": [
        "\n",
        "<br>\n",
        "Q1: Why do RNNs suffer from vanishing or exploding gradients?<br>\n",
        "Write your answer here:<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8HyRWoUiVgE"
      },
      "source": [
        "====================================================<br>\n",
        "TASK 2 — Demonstrate Exploding Gradients <br>\n",
        "===================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7xWZiL4iVgF"
      },
      "outputs": [],
      "source": [
        "rnn = nn.RNN(input_size=1, hidden_size=1, batch_first=True)\n",
        "x = torch.ones((1, 50, 1))  # long sequence\n",
        "target = torch.tensor([1])  # fake label\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(rnn.parameters(), lr=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SceYkkH_iVgG"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Task 2: Exploding Gradients Demonstration ---\")\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXerLwLziVgG"
      },
      "source": [
        "\n",
        "<br>\n",
        "# --- TIP ---<br>\n",
        "You should observe gradient norms growing very large, signifying an exploding gradient problem. Why is that the case? How can you remedy that?<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26j9TnoniVgH"
      },
      "source": [
        "====================================================<br>\n",
        "TASK 3 — Apply Gradient Clipping (15 mins)<br>\n",
        "===================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAyRJ9eEiVgH"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Task 3: Gradient Clipping ---\")\n",
        "rnn = nn.RNN(input_size=1, hidden_size=1, batch_first=True)\n",
        "optimizer = optim.SGD(rnn.parameters(), lr=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHRoraHCiVgI"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMyzZbkLMkvB"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 4: Manual Forward Pass <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlcGh9oLMkvC"
      },
      "outputs": [],
      "source": [
        "def task4_manual_forward_pass():\n",
        "    \"\"\"\n",
        "    Compute a forward pass manually (hidden and output state) for a small LSTM using the activation functions in the formula.\n",
        "    Input sequence length T=3, input size=2, hidden size=2\n",
        "    \"\"\"\n",
        "    x_seq = [np.array([0.5, -1.0]),\n",
        "             np.array([1.0, 0.0]),\n",
        "             np.array([-0.5, 0.5])]\n",
        "    h_prev = np.zeros(2)\n",
        "    # Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWo8cJeZiVgI"
      },
      "source": [
        "====================================================<br>\n",
        "Preprocess IMDB dataset<br>\n",
        "===================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeIIf1ziiVgI"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Loading IMDB dataset ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grfYypcBiVgK"
      },
      "source": [
        "====================================================<br>\n",
        "TASK 5 — Implement LSTM Sentiment Classifier on the IMDB dataset<br>\n",
        "===================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnS_7rGyiVgL"
      },
      "outputs": [],
      "source": [
        "class GRUClassifier(nn.Module):"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "====================================================<br>\n",
        "TASK 6 — Swap LSTM with GRU and repeat Task 4<br>\n",
        "===================================================="
      ],
      "metadata": {
        "id": "P8e_YYtTkfoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ERaPf2BiVgN"
      },
      "outputs": [],
      "source": [
        "class GRUClassifier(nn.Module):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25aw0ZzHkJ_A"
      },
      "source": [
        "====================================================<br>\n",
        "TASK 7 <br>\n",
        "===================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbJO5GwBkJ_B"
      },
      "source": [
        "Compare loss curves for the LSTM and GRU classifiers. Which performs better and why?<br>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}